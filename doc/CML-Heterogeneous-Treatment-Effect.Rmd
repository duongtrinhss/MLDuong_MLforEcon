---
title: "CML-Heterogeneous-Treatment-Effect"
author: "Duong Trinh"
date: "`r Sys.Date()`"
output:
  html_document: 
    toc: true
    toc_float: true
    toc_depth: 3
    number_sections: true
    code_folding: show
  pdf_document: 
    number_sections: true
    extra_dependencies: ["mathtools","bbm"]
bibliography: MLrefs.bib
fontsize: 10pt
keywords: average treatment effect; machine learning; microeconometrics
---


```{r, setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(knitr.table.format = function() {
  if (knitr::is_latex_output()) 'latex' else 'pandoc'
})
```

<!--- For HTML Only --->
`r if (knitr:::is_html_output()) '
$\\newcommand{\\mathbbm}[1]{\\mathbb{#1}}$
'`

# Heterogeneous Treatment Effect
## Neyman-Rubin potential outcome framework:

Assume a distribution $\mathcal{P}$ from which a realization of $N$ independent random variables is given as the training data. That is, $\left(Y_{i}^0, Y_{i}^1, X_{i}, W_{i}\right) \sim \mathcal{P},$ where:

+ $X_{i} \in \mathbb{R}^{d}$ is a $d-$ dimensional covariate or feature vector.

+ $W_{i} \in\{0,1\}$ is the binary treatment assignment indicator. 

+ $Y_{i}^0 \in \mathbb{R}$ is the potential outcome of unit $i$ when $i$ is assigned to the control group $(W_i = 0)$, and $Y_{i}^1$ is the potential outcome when $i$ is assigned to the treatment group $(W_i = 1)$.

To interpret the estimated parameter as a causal relationship, the following assumptions are needed:

### (A1) Conditional Unconfoundedness {-}

$$
Y_i^1, Y_{i}^0 \perp W_{i} \mid X_{i}
$$
The assumption states that, once we condition on observable characteristics, the treatment assignment is independent of how each person would respond to the treatment (two potential outcomes). In other words, the rule that determines whether or not a person is treated is determined completely by their observable characteristics. 

### (A2) Exogeneity of covariates {-}

\begin{equation*}
    X^1_i = X^0_i
\end{equation*}

According to this assumption, the covariates are not affected by the treatment.

### (A3) Overlap Assumption {-}

$$
\forall x \in \operatorname{supp}(X), \quad 0<P(W=1 \mid X=x)<1
$$

This assumption states that we can always find treated and control individuals at every point of the covariate space to compare their outcomes.


### (A4) Stable Unit Treatment Value Assumption (SUTVA) {-}

\begin{equation*}
     Y_i^{obs} = W_i Y_i^1 + (1 - W_i) Y_i^0
\end{equation*}
 
This assumption ensures that there is no interference, no spillover effects, and no hidden variation between treated and control observations.

Now, the fundamental problem of causal inference is that each individual can either receive the treatment or not, thus only one of the two potential outcomes ($Y_{i}^w$) is observable:
\begin{equation}
    Y_i^{obs} = W_i Y_i^1 + (1 - W_i) Y_i^0
\end{equation}

To avoid clutter, denote $Y_i^{obs}$ simply by $Y_i$ from now on.

Hence, the \textit{individual treatment effect} ($ITE$) $\xi_{i}=Y_{i}^{1}-Y_{i}^{0}$ of $W_{i}$ on $Y_{i}$ is never observed, and directly training machine learning methods on this difference is not possible as a result. However, the identification of expectations of $\xi_{i}$ may be possible under plausible assumptions. For example, the identification of the \textit{average treatment effect} ($ATE$) could be defined as $\tau=E\left[\xi_{i}\right]$. My main focus is the \textit{conditional average treatment effects} ($CATEs$). $CATEs$ take the expectations of $\xi_{i}$ conditional on exogenous pre-treatment covariates. Define the finest conditioning level that uses all available covariates $X_{i}$ as the \textit{individualized average treatment effects} ($IATEs$):

\begin{equation}
    \tau(x)=E\left[\xi_{i} \mid X_{i}=x\right]=\mu^{1}(x)-\mu^{0}(x)
\end{equation}

where $\mu^w(x) = \mathbb{E}\left[Y_i^w | X_i = x\right] = \mathbb{E}\left[Y_i| X_i = x, W_i = w\right]$ denotes the conditional expectation of the unobserved potential outcomes.

## Generic Approach

Generic approach decomposes the causal estimation problem into several standard prediction problems and may be combined with a large variety of off-the-shelf machine learning methods (such as the lasso, random forest (RF), Bayesian Adaptive Regression Trees (BART), boosting methods or neural networks). Since the base learners are not designed to estimate the IATEs directly, they are called meta-learners or generic ML algorithms.

+ Reference: 


## Specific Approach
Specific approach includes methods that alter existing machine learning methods to move the target from the estimation of outcomes to the estimation of IATEs. In contrast to meta-learners with a flexible choice of machine learning algorithm, this approach mostly uses modifications of tree-based methods, such as Causal Tree by @athey2016recursive (modifying Regression Tree), Causal Boosting by @powers2018some (modifying Boosting), Causal Forest by @athey2019generalized (modifying Random Forest) or Causal BART by @hahn2020bayesian (modifying Bayesian Additive Regression Tree - BART), etc.

### Causal Tree

Causal Tree is a modified machine learning method invented by @athey2016recursive to alter Regression Tree method for the target of causal inference. The main idea is to partition the covariate space into subpopulations that differ in the magnitude of their treatment effects. The approach enables the construction of valid confidence intervals (unbiased and asymptotically normal estimates) for average treatment effects of groups defined by the tree leaves as long as the "honesty" condition is satisfied. That is, the training sample is split into two parts: one for building the tree (including the cross-validation step) and the another for estimating the treatment effects given leaves of the tree. 

Like Regression Tree, Causal Tree is easy to explain and is more suitable when the model involves non-linear relationships or complex interactions. Meanwhile, this method is limited to trees and does not account for splitting uncertainty, which is important in practical settings.

### Causal Forest 
Causal Forest, which was first introduced by @wager2018estimation and generalized by @athey2019generalized, is the average of a large number of causal trees, where trees differ from one another due to subsampling. The training and prediction procedure of this method is described as follows:

During training, a number of trees are grown on random subsamples of the dataset. Individual trees are trained through the following steps:

+ First, a random subsample is drawn by sampling without replacement from the full dataset. A single root node is created containing this random sample.

+ The root node is split into child nodes, and child nodes are split recursively to form a tree. The procedure stops when no nodes can be split further. Each node is split using the following algorithm:

  + A random subset of variables are selected as candidates to split on.
 
  + For each of these variables $x$, we look at all of its possible values v and consider splitting it into two children based on this value. The goodness of a split $(x, v)$ is determined by how much it increases the heterogeneity in treatment effect between the two child nodes. For computational efficiency, we precompute the gradient of each observation and optimize a linear approximation of this difference.

  + All examples with values for the split variable $x$ that is less than or equal to the split value v are placed in a new left child node, and all examples with values greater than the $v$ are placed in a right child node.

  + If a node has no valid splits, or if splitting will not result in an improved fit, the node is not split further and forms a leaf of the final tree.

When predicting on a test set, we gather a weighted list of the sampleâ€™s neighbors based on what leaf nodes it falls in. We then calculate the treatment effect using the outcomes and treatment status of the neighbor examples. 

In observational studies where self-selection into treatment is present, the first splits might not be a good representation of the treatment effect rather than differences due to confounding variables. To overcome this issue, @athey2019generalized suggest applying Causal Forest local centring. This means that we use the residuals of the outcome and treatment variable as data instead of the original values. It requires two nuisance functions to be trained beforehand to predict the conditional mean which is used to create the residuals.

# Illustration

## **GenericML** package

Reference:

  + [Introduction](https://github.com/mwelz/GenericML/blob/main/slides/useR2022.pdf)
  + [Manual](https://cran.r-project.org/web/packages/GenericML/GenericML.pdf)
  
```{r, message=FALSE}
library(GenericML)
```


## **grf** package

Reference: 

  + [Introduction](https://grf-labs.github.io/grf/articles/grf.html)
  + [Manual](https://cran.r-project.org/web/packages/grf/grf.pdf)

```{r, message=FALSE}
library(grf)
```

# Monte Carlo study

## Design

For each simulation, I specify the sample size $n$, the dimension $d$ of feature space (both low and high dimension setup are considered) as well as the following functions:

+ The treatment propensity: $\pi(x)=\mathbb{P}[W=1 \mid X=x]$

  I consider the constant propensity, i.e. random assignment, balanced case when $\pi(x) = 0.5$ and unbalanced case when $\pi(x)$ is very small; or linear in the sense of logistic function: $\pi(X) = \frac{1}{1+e^{X\beta_{w}+\epsilon}} \mbox{ and } \epsilon \sim N(0,1)$
    
+ The mean effect: $m(x)=2^{-1} \mathbb{E}\left[Y^{(0)}+Y^{(1)} \mid X=x\right]$

  I consider both linear mean effect  $m(x) = X\beta_m$ (when $\beta_m$ is either dense or sparse) ) or non-linear mean effect.

+ The treatment effect: $\tau(x)=\mathbb{E}\left[Y^{(1)}-Y^{(0)} \mid X=x\right]$.
  
  Since this is main interest, I consider some specific cases of $\tau$ to vary the degree of heterogeneity.

+ Thus, the conditional mean effect functions are: $\mu_0(x) = m(x)- 2^{-1}\tau(x )$ and $\mu_1(x) = m(x)+ 2^{-1}\tau(x)$.

Then, to simulate an observation, $i$, in the training set, I simulate its feature vector, $X_i$, its treatment assignment, $W_i$, and its observed outcome, $Y_i$ as below:

+ First, I simulate a $d$-dimensional feature vector $X$:

  + Independent: $X \sim N(0,I_{d\times d})$ or $X \sim U\left[0,1\right]^d$
  
  + Dependent:  $X \sim N(0,\Sigma)$

+ Next, I  simulate the treatment assignment $W$ according to:
    \begin{equation*}
            W \sim Bernouli(\pi(X)) 
        \end{equation*}

+ Finally, I create the observed outcome $Y$:
    \begin{equation*}
        Y \sim N\left[m(X) + (W-0.5)\tau(x), \sigma_Y^2\right]
    \end{equation*}
    where the conditional variance of $Y$ given $X$ and $W$ is $\sigma_Y^2 = 1$ (noise level).

I train each $IATE$ estimator on a training set of $n$ units and then evaluate its performance against a test set of $n_{test}$ units for which the true effect is known. I replicate each experiment $R = 30$ times for large sample ($n = 5000$) and $R =150$ times for small sample ($n \leq 1000$).

### DGP1: Low dimensional data; No confounding; Balanced propensity; Linear mean effect; No treatment effect {-}


$$    
n \in \{1000,5000\}; \quad n_{test} = 1000; \quad d \in \{5, 10, 20\}
$$
$$
X \sim N(0,I_{d\times d})
$$
$$
\pi(X) = 0.5
$$
$$
m(X) = \Sigma_{k=1}^{d}\beta_k X_k \hspace{3mm} (\beta_k = \frac{1}{k} \hspace{2mm}\forall k = \overline{1,d})
$$
$$
    \tau(X) = 0
$$

```{r}
# SIMULATION SETUP 1: Low dimensional data; No confounding; 
# Balanced propensity; Linear mean effect; No treatment effect
#
simulation_1 <- function(d){
  # Generate training sample
  n <- 5000
  sigma <- 1
  
  ## Covariates X
  ## Draw a random nxd matrix from MN(M,U,V)
  Mean_mat <- matrix(0, nrow = n, ncol = d)
  U <- I(n)
  V <- I(d)
  #X <- rmatnorm(s=1,Mean.mat,U,V)  # features
  X <- rmatrixnorm(n=1,mean=Mean_mat,U=U,V=V)
  ## Propensity function: e(x) = 0.5 - constant
  W <-  rbinom(n, 1, 0.5)
  
  ## Mean effect function: 
  mean_effect <- function(x){
    b <- rep(0,d)
    for (i in 1:d){
      b[i] <- 1/i
    }
    
    return(x%*%b)
  }
  
  ## Treatment effect function: tau(x)
  treatment_effect <-  function(x){
    0
  }
  Y <- apply(X, 1, mean_effect) + (W - 0.5) * apply(X, 1, treatment_effect) + sigma * rnorm(n)  
  
  # Generate testing sample
  n_test <- 1000
  Mean_mat_test <- matrix(0, nrow = n_test, ncol = d)
  U_test <- I(n_test)
  V_test <- I(d)
  #X_test <- rmatnorm(s=1,Mean.mat.test,U.test,V.test)
  save_the_seed_2 <- .Random.seed
  set.seed(261) # To maintain the testing sample through simulations
  X_test <- rmatrixnorm(n=1,mean=Mean_mat_test,U=U_test,V=V_test)
  .Random.seed <<- save_the_seed_2
  X_test <- as.data.frame(X_test)
  
  ## Calculate true CATE on testing data for evaluation purpose (calculating expected MSE)
  true_effect <-  apply(X_test, 1, treatment_effect)
  
  # Predict CATEs
  print("PostLasso")
  tauhat_pl <- CATE_PostLasso(Y,W,X,X_test)
  print("CausalTree")
  tauhat_ct <- CATE_CausalTree(Y,W,X,X_test)
  print("CausalForest")
  tauhat_cf <- CATE_CausalForest(Y,W,X,X_test)
  print("XLearner")
  tauhat_xl <- CATE_XLearner(Y,W,X,X_test)
  print("DRLearner")
  tauhat_dr <- CATE_DRLearner(Y,W,X,X_test)
  
  tau_all <- data.frame(true_effect, tauhat_pl,tauhat_ct,tauhat_cf,tauhat_xl,tauhat_dr)
  
  return(tau_all)
}
```

### DGP2: Low dimensional data; No confounding; Balanced propensity; Nonlinear mean effect; Linear treatment effect {-}

$$
n \in \{1000,5000\}; \quad n_{test} = 1000; \quad d \in \{5,10,20\}
$$
$$
X \sim U[0,1]^d
$$
$$
\pi(X) = 0.5
$$
$$
m(X) = \sin(\pi X_1 X_2) + 2(X_3 - 0.5)^2 + X_4 + 0.5 X_5
$$
$$
\tau(X) = \frac{1}{2}(X_1+X_2)
$$

Departing from simulation 1, a more complicated mean effect is taken into account in this setting, i.e. nuisance components are difficult \citep{nie2020quasi}. However, the treatment effect is kept simple. 

```{r}
# SIMULATION 2: Low dimensional data; No confounding; Balanced propensity; 
# Nonlinear mean effect; Linear treatment effect
#

simulation_2 <- function(d){
  # Generate training sample
  n <- 5000
  sigma <- 1
  
  ## Covariates X
  X <-  matrix(runif(n * d, 0, 1), n, d)  # features
  
  ## Propensity function: e(x) = 0.5 - constant
  W <-  rbinom(n, 1, 0.5)
  
  ## Mean effect function: 
  mean_effect <- function(x){
    sin(pi*x[1]*x[2]) + 2*(x[3] - 0.5)^2 + x[4] + 0.5*x[5]
  }
  
  ## Treatment effect function: tau(x)
  treatment_effect <-  function(x) {
    1/2*(x[1]+x[2])
  } 
    Y <- apply(X, 1, mean_effect) + (W - 0.5) * apply(X, 1, treatment_effect) + sigma * rnorm(n)  
  
  # Generate testing sample
  n_test <- 1000
  save_the_seed <- .Random.seed
  set.seed(261) # To maintain the testing sample through simulations
  X_test <-  matrix(runif(n_test * d, 0, 1), n_test, d)
  .Random.seed <<- save_the_seed
  X_test <- as.data.frame(X_test)
  
  ## Calculate true CATE on testing data for evaluation purpose (calculating expected MSE)
  true_effect <-  apply(X_test, 1, treatment_effect)
  
  # Predict CATEs
  print("PostLasso")
  tauhat_pl <- CATE_PostLasso(Y,W,X,X_test)
  print("CausalTree")
  tauhat_ct <- CATE_CausalTree(Y,W,X,X_test)
  print("CausalForest")
  tauhat_cf <- CATE_CausalForest(Y,W,X,X_test)
  print("XLearner")
  tauhat_xl <- CATE_XLearner(Y,W,X,X_test)
  print("DRLearner")
  tauhat_dr <- CATE_DRLearner(Y,W,X,X_test)
  
  tau_all <- data.frame(true_effect, tauhat_pl,tauhat_ct,tauhat_cf,tauhat_xl,tauhat_dr)
  
  return(tau_all)
}
```


### DGP3: Low dimensional data; No confounding; Balanced propensity; No mean effect; Nonlinear treatment effect {-}

$$
n \in \{1000,5000\}; \quad n_{test} = 1000; d \in \{2,4,6,8\}
$$
$$
X \sim U[0,1]^d
$$
$$
\pi(X) = 0.5 
$$
$$
m(X) = 0 \quad (\beta = 0)
$$
$$
\tau(X) = \zeta(X_1)\zeta(X_2), \quad \zeta(X) = 1 + \frac{1}{1+e^{-20(x-1/3)}}
$$
In contrast to the first two simulations, the treatment effect function in this setting is complex nonlinear. This is motivated by @wager2018estimation to evaluate the ability of machine learning methods to adapt to heterogeneity in $\tau(X)$. The propensity and mean effect functions ($\pi(X)$ and $m(X)$) are held fixed.

```{r}
# SIMULATION 3: Low dimensional data; No confounding; Balanced propensity; 
# No mean effect; Nonlinear treatment effect
#
# Reference: Wager & Athey(2017)
#
simulation_3 <- function(d){
  # Generate training sample
  n <- 5000
  sigma <- 1
  
  ## Covariates X
  X <-  matrix(runif(n * d, 0, 1), n, d)  # features
  
  ## Propensity function: e(x) = 0.5 - constant
  W <-  rbinom(n, 1, 0.5)
  
  ## Mean effect function: m(x) = 0 - constant
  
  ## Treatment effect function: tau(x)
  treatment_effect <-  function(x) {
    (1 + 1 / (1 + exp(-20 * (x[1] - 1/3)))) * (1 + 1 / (1 + exp(-20 * (x[2] - 1/3))))
  } # Equation (28) for heterogeneity effect
  
  Y <-  (W - 0.5) * apply(X, 1, treatment_effect) + sigma * rnorm(n)  
  
  # Generate testing sample
  n_test <- 1000
  save_the_seed <- .Random.seed
  set.seed(261) # To maintain the testing sample through simulations
  X_test <-  matrix(runif(n_test * d, 0, 1), n_test, d)
  .Random.seed <<- save_the_seed
  X_test <- as.data.frame(X_test)
  
  ## Calculate true CATE on testing data for evaluation purpose (calculating expected MSE)
  true_effect <-  apply(X_test, 1, treatment_effect)
  
  # Predict CATEs
  print("PostLasso")
  tauhat_pl <- CATE_PostLasso(Y,W,X,X_test)
  print("CausalTree")
  tauhat_ct <- CATE_CausalTree(Y,W,X,X_test)
  print("CausalForest")
  tauhat_cf <- CATE_CausalForest(Y,W,X,X_test)
  print("XLearner")
  tauhat_xl <- CATE_XLearner(Y,W,X,X_test)
  print("DRLearner")
  tauhat_dr <- CATE_DRLearner(Y,W,X,X_test)
  
  tau_all <- data.frame(true_effect, tauhat_pl,tauhat_ct,tauhat_cf,tauhat_xl,tauhat_dr)
  
  return(tau_all)
}
```


### DGP4: Low dimensional data; No confounding; Unbalanced propensity; Linear mean effect; Linear treatment effect {-}

$$
n \in \{1000,5000\}; \quad n_{test} = 1000; \quad d \in \{2,5,8\}
$$
$$
X \sim N(0,I_{d\times d})
$$
$$
\pi(X) = 0.1
$$
$$
m(X) = X^T\beta \hspace{3mm} (\beta \sim U = [-1,1]^d) 
$$
$$
\tau(X) = 6.\mathbb{I}(X_1>0) + 8.\mathbb{I}(X_2>0)
$$

In this setting, the treatment group sizes are very unbalanced - $\pi(X) = 0.1$, i.e., on average only ten percent of the units receive treatment. It reflects the fact that treatment might be expensive in many cases of randomized control trials. Furthermore, I choose the treatment effect function ($\tau(X)$) that is quite simpler to estimate than the mean effect. 

```{r}
# SIMULATION 4: Low dimensional data; No confounding; Unbalanced propensity propensity; 
# Linear, dense/sparse mean effect; Linear treatment effect
#

simulation_4 <- function(d){
  # Generate training sample
  n <- 5000
  sigma <- 1
  
  ## Covariates X
  ## Draw a random nxd matrix from MN(M,U,V)
  Mean_mat <- matrix(0, nrow = n, ncol = d)
  U <- I(n)
  V <- I(d)
  #X <- rmatnorm(s=1,Mean.mat,U,V)  # features
  X <- rmatrixnorm(n=1,mean=Mean_mat,U=U,V=V)
  ## Propensity function: e(x) = 0.1 - constant
  W <-  rbinom(n, 1, 0.1)
  
  ## Mean effect function: 
  mean_effect <- function(x){
    save_the_seed_1 <- .Random.seed
    set.seed(208) # To maintain through simulations   
    b <- runif(d, -1, 1)
    .Random.seed <<- save_the_seed_1
    
    return(x%*%b)
    
  }
  
  ## Treatment effect function: tau(x)
  treatment_effect <-  function(x){
    (6*(x[1]>0)*x[1] + 8*(x[2]>0))*x[2]
  }
  Y <- apply(X, 1, mean_effect) + (W - 0.5) * apply(X, 1, treatment_effect) + sigma * rnorm(n)  
  
  # Generate testing sample
  n_test <- 1000
  Mean_mat_test <- matrix(0, nrow = n_test, ncol = d)
  U_test <- I(n_test)
  V_test <- I(d)
  #X_test <- rmatnorm(s=1,Mean.mat.test,U.test,V.test)
  save_the_seed_2 <- .Random.seed
  set.seed(261) # To maintain the testing sample through simulations
  X_test <- rmatrixnorm(n=1,mean=Mean_mat_test,U=U_test,V=V_test)
  .Random.seed <<- save_the_seed_2
  X_test <- as.data.frame(X_test)
  
  ## Calculate true CATE on testing data for evaluation purpose (calculating expected MSE)
  true_effect <-  apply(X_test, 1, treatment_effect)
  
  # Predict CATEs
  print("PostLasso")
  tauhat_pl <- CATE_PostLasso(Y,W,X,X_test)
  print("CausalTree")
  tauhat_ct <- CATE_CausalTree(Y,W,X,X_test)
  print("CausalForest")
  tauhat_cf <- CATE_CausalForest(Y,W,X,X_test)
  print("XLearner")
  tauhat_xl <- CATE_XLearner(Y,W,X,X_test)
  print("DRLearner")
  tauhat_dr <- CATE_DRLearner(Y,W,X,X_test)
  
  tau_all <- data.frame(true_effect, tauhat_pl,tauhat_ct,tauhat_cf,tauhat_xl,tauhat_dr)
  
  return(tau_all)
}
```


### DGP5: Low dimensional data; Confounding; Linear, sparse mean effect; Nonlinear treatment effect {-}

$$
n \in \{1000,5000\}; \quad n_{test} = 1000; \quad d \in \{2,4,6\}
$$
$$
X \sim U[0,1]^d
$$
$$
\pi(X) = \frac{1}{4}(1+\beta_{2,4}(X_1))
$$
$$
m(X) = 2X_1-1
$$
$$
\tau(X) = \zeta(X_1)\zeta(X_2), \quad \zeta(X) = 1 + \frac{1}{1+e^{-20(x-1/3)}}
$$
where $\beta_{a; b}$ is the $\beta$-density with shape
parameters $a$ and $b$.

```{r}
# SIMULATION 5: Low dimensional data; Confounding;
# Linear, sparse mean effect; Nonlinear treatment effect
#

simulation_5 <- function(d){
  # Generate training sample
  n <- 5000
  sigma <- 1
  
  ## Covariates X
  X <-  matrix(runif(n * d, 0, 1), n, d)  # features
  
  ## Propensity function: 
  propensity <- function(x){
    save_the_seed_1 <- .Random.seed
    set.seed(208)
    cf <- dbeta(x[1], 2, 4)
    .Random.seed <<- save_the_seed_1
    
    return(((1 + cf)/4))
    
    }
  W <-  rbinom(n, 1, apply(X,1,propensity))
  
  ## Mean effect function: 
  mean_effect <- function(x){
    
    (2*x[1] -1)
    
  }
  
  ## Treatment effect function: tau(x)
  treatment_effect <-  function(x) {
    
    (1 + 1 / (1 + exp(-20 * (x[1] - 1/3)))) * (1 + 1 / (1 + exp(-20 * (x[2] - 1/3))))
    
  } # Equation (28) for heterogeneity effect
  
  ## Outcome
  Y <-  (W - 0.5) * apply(X, 1, treatment_effect) + sigma * rnorm(n)  
  
  # Generate testing sample
  n_test <- 1000
  save_the_seed_2 <- .Random.seed
  set.seed(261) # To maintain the testing sample through simulations
  X_test <-  matrix(runif(n_test * d, 0, 1), n_test, d)
  .Random.seed <<- save_the_seed_2
  X_test <- as.data.frame(X_test)
  ## Calculate true CATE on testing data for evaluation purpose (calculating expected MSE)
  true_effect <-  apply(X_test, 1, treatment_effect)
  
  # Predict CATEs
  print("PostLasso")
  tauhat_pl <- CATE_PostLasso(Y,W,X,X_test)
  print("CausalTree")
  tauhat_ct <- CATE_CausalTree(Y,W,X,X_test)
  print("CausalForest")
  tauhat_cf <- CATE_CausalForest(Y,W,X,X_test)
  print("XLearner")
  tauhat_xl <- CATE_XLearner(Y,W,X,X_test)
  print("DRLearner")
  tauhat_dr <- CATE_DRLearner(Y,W,X,X_test)
  
  tau_all <- data.frame(true_effect, tauhat_pl,tauhat_ct,tauhat_cf,tauhat_xl,tauhat_dr)
  
  return(tau_all)
}

# Simulation for Causal Forest local centering

simulation_5b <- function(d){
  # Generate training sample
  n <- 5000
  sigma <- 1
  
  ## Covariates X
  X <-  matrix(runif(n * d, 0, 1), n, d)  # features
  
  ## Propensity function: 
  propensity <- function(x){
    save_the_seed_1 <- .Random.seed
    set.seed(208)
    cf <- dbeta(x[1], 2, 4)
    .Random.seed <<- save_the_seed_1
    
    return(((1 + cf)/4))
    
  }
  W <-  rbinom(n, 1, apply(X,1,propensity))
  
  ## Mean effect function: 
  mean_effect <- function(x){
    
    (2*x[1] -1)
    
  }
  
  ## Treatment effect function: tau(x)
  treatment_effect <-  function(x) {
    
    (1 + 1 / (1 + exp(-20 * (x[1] - 1/3)))) * (1 + 1 / (1 + exp(-20 * (x[2] - 1/3))))
    
  } # Equation (28) for heterogeneity effect
  
  ## Outcome
  Y <-  (W - 0.5) * apply(X, 1, treatment_effect) + sigma * rnorm(n)  
  
  # Generate testing sample
  n_test <- 1000
  save_the_seed_2 <- .Random.seed
  set.seed(261) # To maintain the testing sample through simulations
  X_test <-  matrix(runif(n_test * d, 0, 1), n_test, d)
  .Random.seed <<- save_the_seed_2
  X_test <- as.data.frame(X_test)
  ## Calculate true CATE on testing data for evaluation purpose (calculating expected MSE)
  true_effect <-  apply(X_test, 1, treatment_effect)
  
  # Predict CATEs
  print("CausalForest local centering")
  tauhat_cf_lc <- CATE_CausalForest_lc(Y,W,X,X_test)

  
  tau_all <- data.frame(true_effect, tauhat_cf_lc)
  
  return(tau_all)
}
```

So far, only a randomized experiment has been examined, i.e., constant propensity. This setting is intended to emulate a problem in observational studies: a treatment assignment is often correlated with potential outcomes. Modifying the setup of simulation 3, \citet{athey2019generalized} introduce an interaction between $\pi(x)$ and $m(x)$. Both the selection bias arising from such interaction and the heterogeneous treatment effect ($\tau(x)$) are presented in this setup.

### DGP6: High dimensional data; No Confounding; Balanced propensity; No mean effect; Nonlinear treatment effect {-}

$$
(n, n_{test},d) \in \{(200,200,400);(300,300,300);(400,400,200)\}
$$
$$
X \sim U[0,1]^d
$$
$$
\pi(X) = 0.5
$$
$$
m(X) = 0 
$$
$$
\tau(X) = \zeta(X_1)\zeta(X_2), \quad \zeta(X) = 1 + \frac{1}{1+e^{-20(x-1/3)}}
$$
So far, only low dimensional data has been considered. I modify simulation 3 by examining different values of $(n, n_{test},d)$, in which d is relatively large, and keep other parameters the same to evaluate the performance of machine learning causal estimators. High dimensional settings arise in many empirical problems, especially in current RCT where the number of baseline covariates is potentially very large.

```{r}
# SIMULATION 6: High dimensional data; No Confounding; Balanced propensity propensity; 
# No mean effect; Nonlinear treatment effect
#

simulation_6 <- function(d){
  # Generate training sample
  n <- 200
  sigma <- 1
  
  ## Covariates X
  X <-  matrix(runif(n * d, 0, 1), n, d)  # features
  
  ## Propensity function: e(x) = 0.5 - constant
  W <-  rbinom(n, 1, 0.5)
  
  ## Mean effect function: m(x) = 0 - constant
  
  ## Treatment effect function: tau(x)
  treatment_effect <-  function(x) {
    (1 + 1 / (1 + exp(-20 * (x[1] - 1/3)))) * (1 + 1 / (1 + exp(-20 * (x[2] - 1/3))))
  } # Equation (28) for heterogeneity effect
  
  Y <-  (W - 0.5) * apply(X, 1, treatment_effect) + sigma * rnorm(n)  
  
  # Generate testing sample
  n_test <- 200
  save_the_seed <- .Random.seed
  set.seed(261) # To maintain the testing sample through simulations
  X_test <-  matrix(runif(n_test * d, 0, 1), n_test, d)
  .Random.seed <<- save_the_seed
  X_test <- as.data.frame(X_test)
  ## Calculate true CATE on testing data for evaluation purpose (calculating expected MSE)
  true_effect <-  apply(X_test, 1, treatment_effect)
  
  # Predict CATEs
  print("PostLasso")
  tauhat_pl <- CATE_PostLasso(Y,W,X,X_test)
  print("CausalTree")
  tauhat_ct <- CATE_CausalTree(Y,W,X,X_test)
  print("CausalForest")
  tauhat_cf <- CATE_CausalForest(Y,W,X,X_test)
  print("XLearner")
  tauhat_xl <- CATE_XLearner(Y,W,X,X_test)
  print("DRLearner")
  tauhat_dr <- CATE_DRLearner(Y,W,X,X_test)
  
  tau_all <- data.frame(true_effect, tauhat_pl,tauhat_ct,tauhat_cf,tauhat_xl,tauhat_dr)
  
  return(tau_all)
}
```


## Performance Metrics
For the prediction of each observation $j$ in the testing sample, I consider four major performance measures: 

+ Mean Squared Error ($MSE$):
$$
MSE_{j} = \frac{1}{R} \sum\limits_{r=1}^{R}\left[\xi\left(x_{j}, y_{j}^{0}\right)-\hat{\tau}\left(x_{j}\right)_{r}\right]^{2}
$$
+ Absolute Bias ($|Bias|$):
$$
|Bias_{j}| = \mid\underbrace{\frac{1}{R} \sum_{r=1}^{R} \hat{\tau}\left(x_{j}\right)_{r}}_{\overline{\hat{\tau}}\left(x_{j}\right)_{r}}-\xi\left(x_{j}, y_{j}^{0}\right) \mid 
$$
+ Standard Deviation ($SD$):
$$
SD_{j}=\sqrt{\frac{1}{R}\sum_{r=1}^{R}\left[\hat{\tau}\left(x_{j}\right)_{r}-\overline{\hat{\tau}}\left(x_{j}\right)_{r}\right]^{2}}
$$

+ Coverage Rate for $95\%$ confidence interval ($Coverage$): 
$$
Coverage = \frac{1}{R}\sum_{r=1}^{R}\mathbb{I}\{\overline{\hat{\tau}}\left(x_{j}\right)_{r} - 1.96*SD_j\leq \hat{\tau}\left(x_{j}\right)_{r} \leq \overline{\hat{\tau}}\left(x_{j}\right)_{r} + 1.96*SD_j\}
$$
Since 1000 parameters are corresponding to 1000 observations in the testing sample; I summarize the performance over the whole testing sample by taking the averages $\overline{MSE}$, $\overline{|Bias|}$, $\overline{SD}$ and $\overline{Coverage}$.

```{r}
 # Define comparison metrics for ML estimators
  MSE <- function(tauhat_mt){
    df <- (tauhat_mt - true_effect_mt)^2
    MSE <- apply(df,1,mean)
    return(MSE)
  }
  
  Bias <- function(tauhat_mt){
    Bias <- abs(apply(tauhat_mt-true_effect_mt,1,mean))
    return(Bias)
  }
  
  SD <- function(tauhat_mt){
    sehat <- apply(tauhat_mt,1,sd)
    return(sehat)
  }
  
  Coverage <- function(tauhat_mt){
    sehat <- apply(tauhat_mt,1,sd)
    df <- abs(tauhat_mt-true_effect_mt) <= 1.96 * sehat
    Coverage <- apply(df,1,mean)
    return(Coverage)
  }
```

# SGPE Lab

```{r, message=FALSE}
# load data, available in GitHub repo mwelz/GenericML
url_data <-
url(paste0(
"https://github.com/mwelz/GenericML/blob/main/slides",
"/data/morocco_preprocessed.Rdata?raw=true"
))
load(url_data)
```

```{r}
# Generic ML
library("GenericML")
# Causal forests
library(grf)
if(packageVersion("grf") < '0.10.2') {
warning("This script requires grf 0.10.2 or higher")
}
```

```{r}
library("estimatr")
OLSfit <- lm_robust(Y~D+Z,clusters=demi_paire)
# str(OLSfit$coefficients)
# str(OLSfit$std.error)

```

## Generic ML

We will use the `GenericML` function from the package of same name. Do have a look at the help file. It comes with plenty of options. We need to make some preparations before we can call it.

### Selecting learners

The package `GenericML` utilizes the `mlr3` environment. Since Generic ML allows us to utilize almost any machine learner, we create a vector with cross-validated lasso and extreme gradient boosting.

Note that we omit the `classif.` or `regr.`-prefix (see help file `?GenericML`).

```{r}
library("mlr3verse")
# specify learners
learners <-
  c("mlr3::lrn('ranger')",
   "mlr3::lrn('cv_glmnet', s = 'lambda.min', alpha = 0.5)",
   "mlr3::lrn('svm')",
   "mlr3::lrn('xgboost')")
```

### Specify variance-covariance estimator

Use the function `setup_vcov()` to select a cluster-robust var-covariance estimator. Cluster by `demi_paire`. Store the resulting object in `vcov`.

```{r}
# calls functions from the "sandwich" package
# cluster standard errors along "demi_paire"
vcov <- setup_vcov(estimator = "vcovCL",
                   arguments = list(cluster = demi_paire))
```

### Specify the X1 matrix

The `setup_X1()` function sets the content of the $X_1$ matrix as controls. We add both the base line proxy estimates as well as the proxy treatment effects. In addition, we control from village-pair level fixed effects. 

```{r}
# include BCA and CATE controls
# add fixed effects along variable "vil_pair"
X1 <- setup_X1(funs_Z = c("B", "S"),
               fixed_effects = vil_pair)
```

### Run `GenericML`

We now run the estimation. The code below uses `num_splits=100`, but if you have enough computational power, try to set `num_splits=100`.

```{r}
# run GenericML()
genML <- GenericML(
  Z = Z, D = D, Y = Y,                      # observed data
  learners_GenericML = learners,            # learners
  learner_propensity_score = "constant",    # = 0.5 (RCT)
  num_splits = 20, #100L,                    # number splits
  quantile_cutoffs = c(0.2, 0.4, 0.6, 0.8), # grouping
  significance_level = 0.05,                # significance level
  X1_BLP = X1, X1_GATES = X1,               # regression setup
  vcov_BLP = vcov, vcov_GATES = vcov,       # covariance setup
  parallel = TRUE, num_cores = 6L,          # parallelization
  seed = 20220621)                          # RNG seed
```

### Testing for heterogeneity

What does the test for heterogeneity below indicate?

```{r}
# BLP
results_BLP <- get_BLP(genML,plot=FALSE)
results_BLP 
```

### Testing for heterogeneity

Estimate and plot the GATES effects using the `get_GATES()` function. Is the difference between group 1's and group 5's treatment effect significant?

```{r}
# GATES
results_GATES <- get_GATES(genML, plot = TRUE)
results_GATES
```

### Testing for heterogeneity

Looking at the results from the CLAN below, does the GATES vary with the age of the household head (`head_age_bl`)?

```{r}
# CLAN
results_CLAN <- get_CLAN(genML, variable = "head_age_bl", plot = TRUE)
results_CLAN
```

## Causal forest

### Grow the causal forest

```{r}
# CLAN
Y.forest = regression_forest(Z, Y, clusters = demi_paire)
Y.hat = predict(Y.forest)$predictions
D.forest = regression_forest(Z, D, clusters = demi_paire)
D.hat = predict(D.forest)$predictions

cf.raw = causal_forest(Z, Y, D,
                       Y.hat = Y.hat, W.hat = D.hat,
                       clusters =  demi_paire)
tau.hat = predict(cf.raw)$predictions
```

### Remove irrelevant variables

The authors recommend to remove irrelevant variables. The function `variable_importance()` tells us how important each variable is. to Remove all variables that have lower than average importance. Also, add the option `tune.parameters = "all"`.

```{r}
varimp = variable_importance(cf.raw)
selected.idx = which(varimp > mean(varimp))

cf = causal_forest(Z[,selected.idx], Y, D,
                   Y.hat = Y.hat, W.hat = D.hat,
                   clusters = demi_paire,
                   tune.parameters = "all")
```

After you have fitted the refined causal forest, save the estimated effects:

```{r}
tau.hat = predict(cf)$predictions
```

### Estimate ATE

```{r}
ATE = average_treatment_effect(cf)
paste("95% CI for the ATE:", round(ATE[1], 3),
      "+/-", round(qnorm(0.975) * ATE[2], 3))
```

### Testing for heterogeneity 1/2

The authors suggest to test average below-median against average above-median treatment effects to test for heterogeneity. What do you find?

```{r}
high_effect = tau.hat > median(tau.hat)
ate.high = average_treatment_effect(cf, subset = high_effect)
ate.low = average_treatment_effect(cf, subset = !high_effect)
paste("95% CI for difference in ATE:",
      round(ate.high[1] - ate.low[1], 3), "+/-",
      round(qnorm(0.975) * sqrt(ate.high[2]^2 + ate.low[2]^2), 3))
```

### Testing for heterogeneity 2/2

The package also comes with a function that implements the heterogeneity test from the Generic ML article. The function is called `test_calibration()`. What do you find?

```{r}
test_calibration(cf)
```

### Exploring heterogeneity

Finally, explore the relationship between effect size and the age of the household age. Do you find similar results as when applying CLAN?

```{r}
df <- data.frame(head_age_bl=Z[,"head_age_bl"],tau.hat=tau.hat)
summary(lm(tau.hat~head_age_bl,data=df))
summary(lm(tau.hat~head_age_bl+I(head_age_bl*head_age_bl),data=df))
```

# Reference {-}